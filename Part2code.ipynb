{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing all necessary libraries. Additionally, downlaoding resources required by the NLTK (Natural Language Toolkit) library. Resources such as tokenizers, stop words, sentiment lexicons, named entity chunkers, and other data used by NLTK for natural language processing(NLP) tasks."
      ],
      "metadata": {
        "id": "3xYw-zxCQWoM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_F6neL8EQH3w",
        "outputId": "8598143c-8d93-4328-96c5-3123d82009c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Download NLTK resources if not already downloaded\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This part of the code performing NER, Sentiment analysis and preprocessing of the text.\n"
      ],
      "metadata": {
        "id": "5L6ugNWBRFSg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform NER on a given text\n",
        "def perform_ner(text):\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    ner_entities = []\n",
        "    for sentence in sentences:\n",
        "        words1 = word_tokenize(sentence)\n",
        "        pos_tags = nltk.pos_tag(words1)\n",
        "        ner_tags = nltk.ne_chunk(pos_tags)\n",
        "        for chunk in ner_tags:\n",
        "            if hasattr(chunk, 'label'):\n",
        "                entity1 = ' '.join(c[0] for c in chunk.leaves())\n",
        "                entity_type = chunk.label()\n",
        "                ner_entities.append((entity1, entity_type))\n",
        "    return ner_entities\n",
        "\n",
        "# Initialize the VADER sentiment analyzer\n",
        "sen = SentimentIntensityAnalyzer()\n",
        "# Function to perform sentiment analysis on a given text\n",
        "def analyze_sentiment(text):\n",
        "    scores = sen.polarity_scores(text)\n",
        "    if scores['compound'] >= 0.05:\n",
        "        return 'Positive'\n",
        "    elif scores['compound'] <= -0.05:\n",
        "        return 'Negative'\n",
        "    else:\n",
        "        return 'Neutral'\n",
        "\n",
        "\n",
        "# Initialize WordNet lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "# Define a function for text preprocessing with lemmatization\n",
        "def preprocess_text(text):\n",
        "    # Tokenize the text and perform lemmatization\n",
        "    token_data = word_tokenize(text)\n",
        "    lemma_tokens = [lemmatizer.lemmatize(token) for token in token_data]\n",
        "\n",
        "    # Remove punctuation and stopwords\n",
        "    filteredtoken = [word.lower() for word in lemma_tokens if word.isalnum() and word.lower() not in stopwords.words('english')]\n",
        "\n",
        "    # Join the tokens back into a single string\n",
        "    preprocessed_text = ' '.join(filteredtoken)\n",
        "\n",
        "    return preprocessed_text"
      ],
      "metadata": {
        "id": "0i4-2tThRGA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the below step , we are defining the path of the dataset. Initializing the empty list to store the preprocessed data. Reading each file from each category and performing NER, sentiment analysis and preprocessing. In the empty dataset appending the preprocessed data after applying these features.\n",
        "\n"
      ],
      "metadata": {
        "id": "QESOvLUfTi97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the dataset\n",
        "\n",
        "data_class_path = \"C:/Users/c23084426/Downloads/bbc\"\n",
        "data = []\n",
        "cat = ['tech', 'business', 'sport', 'politics', 'entertainment']\n",
        "\n",
        "# Dictionary to store NER results for each category\n",
        "ner_results = {category: [] for category in cat}\n",
        "\n",
        "# Perform NER for each text file in each category\n",
        "for category in cat:\n",
        "    cat_path = os.path.join(data_class_path, category)\n",
        "    files = os.listdir(cat_path)\n",
        "    for file in files:\n",
        "        with open(os.path.join(cat_path, file), 'r', encoding='latin-1') as f:\n",
        "            text = f.read()\n",
        "            ner_entities = perform_ner(text)\n",
        "            ner_results[category].extend(ner_entities)\n",
        "\n",
        "            # Perform sentiment analysis\n",
        "            sentiment = analyze_sentiment(text)\n",
        "\n",
        "            # Preprocess the text before adding to data\n",
        "            preprocessed_text = preprocess_text(text)\n",
        "\n",
        "            data.append({'text': preprocessed_text, 'category': category, 'sentiment': sentiment})\n",
        "\n",
        "# Create a DataFrame from the preprocessed data\n",
        "df = pd.DataFrame(data)\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NqVdvjATh66",
        "outputId": "590a3d52-0ca5-462a-e61e-f440c9dbf84a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2225 entries, 0 to 2224\n",
            "Data columns (total 3 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   text       2225 non-null   object\n",
            " 1   category   2225 non-null   object\n",
            " 2   sentiment  2225 non-null   object\n",
            "dtypes: object(3)\n",
            "memory usage: 52.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying TF-IDF method for word count frequency measure and then combing all features for feature selection. Using chi-squared test considering only 1000 top feature for further processing."
      ],
      "metadata": {
        "id": "9fTTG4AVWGsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Extraction using TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=1000, norm='l2')  # Add norm='l2' for normalization # You can adjust max_features as needed\n",
        "X_tfidf_Vector = tfidf_vectorizer.fit_transform(df['text'])\n",
        "#X = tfidf_vectorizer.fit_transform(df['text'])\n",
        "\n",
        "if X_tfidf_Vector.min() < 0:\n",
        "    print(\"Negative values found in TF-IDF features!\")\n",
        "\n",
        "df['ner_entities'] = df['text'].apply(perform_ner)\n",
        "\n",
        "# Convert sentiment to numerical values\n",
        "df['sentiment_numeric'] = df['sentiment'].apply(lambda x: 1 if x == 'Positive' else (-1 if x == 'Negative' else 0))\n",
        "\n",
        "# Get NER feature counts\n",
        "ner_features = np.array([len(ner) for ner in df['ner_entities']]).reshape(-1, 1)\n",
        "\n",
        "# Combine features\n",
        "All_combined_features = np.concatenate((X_tfidf_Vector.toarray(), df['sentiment_numeric'].values.reshape(-1, 1), ner_features), axis=1)\n",
        "\n",
        "# Ensure non-negativity of features\n",
        "All_combined_features = np.maximum(All_combined_features, 0)\n",
        "\n",
        "# Apply feature selection using Chi-squared test\n",
        "k_best_features = 1000  # Specify the number of features to select\n",
        "selector = SelectKBest(score_func=chi2, k=k_best_features)\n",
        "selected_features_data = selector.fit_transform(All_combined_features, df['category'])\n",
        "\n",
        "# Split the data into features (X) and target variable (y)\n",
        "X = selected_features_data\n",
        "y = df['category']\n"
      ],
      "metadata": {
        "id": "bAR0JozlWRur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The matrix is created after chi-squatred test with top 1000 features, and splitted into training ,development and test set. We are using SVM classfier on traning ,development and test data to train the classification model and calculate accuracy. The high accuracy implies the classification model works properly in categorizing five different news articles."
      ],
      "metadata": {
        "id": "zJyZhtFnYj3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training, development, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "X_dev, X_test, y_dev, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "# Initialize SVM classifier\n",
        "svm_classifier = SVC(kernel='linear', random_state=42)\n",
        "\n",
        "# Train the SVM classifier on the training data\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predictions on the training set\n",
        "train_predictions_class = svm_classifier.predict(X_train)\n",
        "\n",
        "# Evaluate the performance of the model on the training set\n",
        "print(\"Classification Report on Training Set:\")\n",
        "print(classification_report(y_train, train_predictions_class))\n",
        "\n",
        "# Predictions on the development set\n",
        "dev_predictions_class = svm_classifier.predict(X_dev)\n",
        "\n",
        "# Evaluate the performance of the model on the development set\n",
        "print(\"Classification Report on Development Set:\")\n",
        "print(classification_report(y_dev, dev_predictions_class))\n",
        "\n",
        "# Predictions on the test set\n",
        "test_predictions_class = svm_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the model on the test set\n",
        "print(\"Classification Report on Test Set:\")\n",
        "print(classification_report(y_test, test_predictions_class))\n",
        "\n",
        "# Calculate accuracy on the training set\n",
        "trainaccuracy_ondata = accuracy_score(y_train, train_predictions_class)\n",
        "print(\"Accuracy on Training Set:\", trainaccuracy_ondata)\n",
        "\n",
        "# Calculate accuracy on the development set\n",
        "devaccuracy_ondata = accuracy_score(y_dev, dev_predictions_class)\n",
        "print(\"Accuracy on Development Set:\", devaccuracy_ondata)\n",
        "\n",
        "# Calculate accuracy on the test set\n",
        "testaccuracy_ondata = accuracy_score(y_test, test_predictions_class)\n",
        "print(\"Accuracy on Test Set:\", testaccuracy_ondata)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NzvW2zQXkX9",
        "outputId": "4a33d6df-9579-4735-85cb-e8b38dffb421"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report on Training Set:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     business       1.00      0.99      1.00       357\n",
            "entertainment       1.00      1.00      1.00       270\n",
            "     politics       0.99      1.00      0.99       292\n",
            "        sport       1.00      1.00      1.00       357\n",
            "         tech       1.00      1.00      1.00       281\n",
            "\n",
            "     accuracy                           1.00      1557\n",
            "    macro avg       1.00      1.00      1.00      1557\n",
            " weighted avg       1.00      1.00      1.00      1557\n",
            "\n",
            "Classification Report on Development Set:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     business       0.97      0.97      0.97        76\n",
            "entertainment       0.96      0.93      0.95        58\n",
            "     politics       0.95      0.97      0.96        63\n",
            "        sport       1.00      1.00      1.00        77\n",
            "         tech       0.98      1.00      0.99        60\n",
            "\n",
            "     accuracy                           0.98       334\n",
            "    macro avg       0.97      0.97      0.97       334\n",
            " weighted avg       0.98      0.98      0.98       334\n",
            "\n",
            "Classification Report on Test Set:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     business       0.97      0.92      0.95        77\n",
            "entertainment       0.98      1.00      0.99        58\n",
            "     politics       1.00      0.95      0.98        62\n",
            "        sport       0.99      1.00      0.99        77\n",
            "         tech       0.92      1.00      0.96        60\n",
            "\n",
            "     accuracy                           0.97       334\n",
            "    macro avg       0.97      0.97      0.97       334\n",
            " weighted avg       0.97      0.97      0.97       334\n",
            "\n",
            "Accuracy on Training Set: 0.9974309569685292\n",
            "Accuracy on Development Set: 0.9760479041916168\n",
            "Accuracy on Test Set: 0.9730538922155688\n"
          ]
        }
      ]
    }
  ]
}